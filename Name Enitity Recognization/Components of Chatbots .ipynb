{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components \n",
    "\n",
    "1. Intent Classification\n",
    "2. Entity Extraction \n",
    "3. Response Selectors \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For Simple Bot \n",
    "1. Intent Classification - done \n",
    "2. Entity extraction - not done \n",
    "3. Response Selector - andom selection \n",
    "\n",
    "\n",
    "Preporcessing \n",
    "1. Tokenization\n",
    "You can process other whitespace-tokenized (words are separated by spaces) languages with the WhitespaceTokenizer. If your language is not whitespace-tokenized, you should use a different tokenizer. We support a number of different tokenizers, or you can create your own custom tokenizer.\n",
    "\n",
    "    \n",
    "2. Featurizing \n",
    "can use pre-trained word embeddings , language model to extract the contextual vector, can \n",
    "also use countvectorizer basically this step converts words to vectors or numbers, which the model can be fed as input.\n",
    "\n",
    "\n",
    "Handling Imbalanced Classes :\n",
    "Classification algorithms often do not perform well if there is a large class imbalance, for example if you have a lot of training data for some intents and very little training data for others. To mitigate this problem, you can use a balanced batching strategy.\n",
    "\n",
    "\n",
    "\n",
    "## To do \n",
    "1. Learn More about Spacy\n",
    "2. implement different entity extraction models \n",
    "3. impement different intent extraction models\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent Classification \n",
    "\n",
    "1. MLP in Keras \n",
    "2. SklearnIntentClassifier Using SVM,NB,LR \n",
    "    rasa uses dense featureizers for this classifer.\n",
    "3. KeyWordIntentClassification : ruled based method :\n",
    "   This classifier works by searching a message for keywords. The matching is case sensitive by default and searches only for exact matches of the keyword-string in the user message. The keywords for an intent are the examples of that intent in the NLU training data. This means the entire example is the keyword, not the individual words in the example.\n",
    "   \n",
    "   \n",
    "Conclusion: Intent Classification task can be treated as a multi class classification or single intent or mulit-label for mulit-intent. \n",
    "\n",
    "We can make use of ml models , simple NN , LStm , and transformer models.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Extractor (important.)\n",
    "\n",
    "1. spany entity extractor \n",
    "2. ntlk puntk  \n",
    "3. CRF (conditional random field)\n",
    "4. Duckling lets you extract common entities like dates, amounts of money, distances, and others in a number of languages.\n",
    "5. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Response Selectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use to predic bots output from a given set of responces\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Entity Recognization (NER) \n",
    "### NER without Using NLTK and SPCAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "European authorities fined Google a \n",
      "record $5.1 billion on Wednesday for \n",
      "abusing its power in the mobile phone \n",
      "market and ordered the company to alter\n",
      "its practices. Reported by James Potter \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data =  '''\n",
    "European authorities fined Google a \n",
    "record $5.1 billion on Wednesday for \n",
    "abusing its power in the mobile phone \n",
    "market and ordered the company to alter\n",
    "its practices. Reported by James Potter \n",
    "'''\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part of speech tagging breaks the word into \n",
    "verb,noun,adjective\n",
    "\n",
    "In Chunking we identify named entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = nltk.word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('European', 'JJ'),\n",
       " ('authorities', 'NNS'),\n",
       " ('fined', 'VBD'),\n",
       " ('Google', 'NNP'),\n",
       " ('a', 'DT'),\n",
       " ('record', 'NN'),\n",
       " ('$', '$'),\n",
       " ('5.1', 'CD'),\n",
       " ('billion', 'CD'),\n",
       " ('on', 'IN'),\n",
       " ('Wednesday', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('abusing', 'VBG'),\n",
       " ('its', 'PRP$'),\n",
       " ('power', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('mobile', 'JJ'),\n",
       " ('phone', 'NN'),\n",
       " ('market', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('ordered', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('company', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('alter', 'VB'),\n",
       " ('its', 'PRP$'),\n",
       " ('practices', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Reported', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('James', 'NNP'),\n",
       " ('Potter', 'NNP')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting pos_tag of sent \n",
    "\n",
    "sent = nltk.pos_tag(sent)\n",
    "\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  European/JJ\n",
      "  authorities/NNS\n",
      "  fined/VBD\n",
      "  Google/NNP\n",
      "  (NP a/DT record/NN)\n",
      "  $/$\n",
      "  5.1/CD\n",
      "  billion/CD\n",
      "  on/IN\n",
      "  Wednesday/NNP\n",
      "  for/IN\n",
      "  abusing/VBG\n",
      "  its/PRP$\n",
      "  (NP power/NN)\n",
      "  in/IN\n",
      "  (NP the/DT mobile/JJ phone/NN)\n",
      "  (NP market/NN)\n",
      "  and/CC\n",
      "  ordered/VBD\n",
      "  (NP the/DT company/NN)\n",
      "  to/TO\n",
      "  alter/VB\n",
      "  its/PRP$\n",
      "  practices/NNS\n",
      "  ./.\n",
      "  Reported/VBN\n",
      "  by/IN\n",
      "  James/NNP\n",
      "  Potter/NNP)\n"
     ]
    }
   ],
   "source": [
    "# regex pattern \n",
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('European', 'JJ', 'O'),\n",
      " ('authorities', 'NNS', 'O'),\n",
      " ('fined', 'VBD', 'O'),\n",
      " ('Google', 'NNP', 'O'),\n",
      " ('a', 'DT', 'B-NP'),\n",
      " ('record', 'NN', 'I-NP'),\n",
      " ('$', '$', 'O'),\n",
      " ('5.1', 'CD', 'O'),\n",
      " ('billion', 'CD', 'O'),\n",
      " ('on', 'IN', 'O'),\n",
      " ('Wednesday', 'NNP', 'O'),\n",
      " ('for', 'IN', 'O'),\n",
      " ('abusing', 'VBG', 'O'),\n",
      " ('its', 'PRP$', 'O'),\n",
      " ('power', 'NN', 'B-NP'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('mobile', 'JJ', 'I-NP'),\n",
      " ('phone', 'NN', 'I-NP'),\n",
      " ('market', 'NN', 'B-NP'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('ordered', 'VBD', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('company', 'NN', 'I-NP'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('alter', 'VB', 'O'),\n",
      " ('its', 'PRP$', 'O'),\n",
      " ('practices', 'NNS', 'O'),\n",
      " ('.', '.', 'O'),\n",
      " ('Reported', 'VBN', 'O'),\n",
      " ('by', 'IN', 'O'),\n",
      " ('James', 'NNP', 'O'),\n",
      " ('Potter', 'NNP', 'O')]\n"
     ]
    }
   ],
   "source": [
    "#IOB tags have become the standard way to represent chunk structures in files, and we will also be using this format.\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint \n",
    "\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "pprint(iob_tagged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keywords here are :\n",
    "\n",
    "    Each entry has toekn,pos-tag,named_entity_tag\n",
    "   \n",
    "pos-tag is different from names-entity tag \n",
    "\n",
    "pos-tag : highlights the gramatical nature of the \n",
    "    word/ token if its a noun , verb , adjective etc.\n",
    "    \n",
    "name-entity-tagging : Each token is identified with some \n",
    "    entity like name of place Europe is GPE, \n",
    "    Google is organization etc.\n",
    "\n",
    "\n",
    "`With the function nltk.ne_chunk(), we can recognize named entities using a classifier, the classifier adds category labels such as PERSON, ORGANIZATION, and GPE.`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Ghostscript executable isn't found.\n",
      "See http://web.mit.edu/ghostscript/www/Install.htm\n",
      "If you're using a Mac, you can try installing\n",
      "https://docs.brew.sh/Installation then `brew install ghostscript`\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    805\u001b[0m                             \u001b[0menv_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PATH'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m                         )\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    696\u001b[0m         find_binary_iter(\n\u001b[1;32m--> 697\u001b[1;33m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_to_bin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    680\u001b[0m     for file in find_file_iter(\n\u001b[1;32m--> 681\u001b[1;33m         \u001b[0mpath_to_bin\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m     ):\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'='\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration paramaters or set the PATH environment variable.\n===========================================================================",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    817\u001b[0m                                         \"https://docs.brew.sh/Installation then `brew install ghostscript`\")                \n\u001b[0;32m    818\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_error_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [Tree('GPE', [('European', 'JJ')]), ('authorities', 'NNS'), ('fined', 'VBD'), Tree('PERSON', [('Google', 'NNP')]), ('a', 'DT'), ('record', 'NN'), ('$', '$'), ('5.1', 'CD'), ('billion', 'CD'), ('on', 'IN'), ('Wednesday', 'NNP'), ('for', 'IN'), ('abusing', 'VBG'), ('its', 'PRP$'), ('power', 'NN'), ('in', 'IN'), ('the', 'DT'), ('mobile', 'JJ'), ('phone', 'NN'), ('market', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('the', 'DT'), ('company', 'NN'), ('to', 'TO'), ('alter', 'VB'), ('its', 'PRP$'), ('practices', 'NNS'), ('.', '.'), ('Reported', 'VBN'), ('by', 'IN'), Tree('PERSON', [('James', 'NNP'), ('Potter', 'NNP')])])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.ne_chunk(pos_tag(word_tokenize(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEuropean authorities fined Google a \\nrecord $5.1 billion on Wednesday for \\nabusing its power in the mobile phone \\nmarket and ordered the company to alter\\nits practices. Reported by James Potter \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('European', 'NORP'),\n",
       " ('Google', 'ORG'),\n",
       " ('$5.1 billion', 'MONEY'),\n",
       " ('Wednesday', 'DATE'),\n",
       " ('James Potter', 'PERSON')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.text,x.label_) for x in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\n",
      ", 'O', ''),\n",
      " (European, 'B', 'NORP'),\n",
      " (authorities, 'O', ''),\n",
      " (fined, 'O', ''),\n",
      " (Google, 'B', 'ORG'),\n",
      " (a, 'O', ''),\n",
      " (\n",
      ", 'O', ''),\n",
      " (record, 'O', ''),\n",
      " ($, 'B', 'MONEY'),\n",
      " (5.1, 'I', 'MONEY'),\n",
      " (billion, 'I', 'MONEY'),\n",
      " (on, 'O', ''),\n",
      " (Wednesday, 'B', 'DATE'),\n",
      " (for, 'O', ''),\n",
      " (\n",
      ", 'O', ''),\n",
      " (abusing, 'O', ''),\n",
      " (its, 'O', ''),\n",
      " (power, 'O', ''),\n",
      " (in, 'O', ''),\n",
      " (the, 'O', ''),\n",
      " (mobile, 'O', ''),\n",
      " (phone, 'O', ''),\n",
      " (\n",
      ", 'O', ''),\n",
      " (market, 'O', ''),\n",
      " (and, 'O', ''),\n",
      " (ordered, 'O', ''),\n",
      " (the, 'O', ''),\n",
      " (company, 'O', ''),\n",
      " (to, 'O', ''),\n",
      " (alter, 'O', ''),\n",
      " (\n",
      ", 'O', ''),\n",
      " (its, 'O', ''),\n",
      " (practices, 'O', ''),\n",
      " (., 'O', ''),\n",
      " (Reported, 'O', ''),\n",
      " (by, 'O', ''),\n",
      " (James, 'B', 'PERSON'),\n",
      " (Potter, 'I', 'PERSON'),\n",
      " (\n",
      ", 'O', '')]\n"
     ]
    }
   ],
   "source": [
    "#Nord (nationalists or religious or ploitical groups)\n",
    "pprint([(X, X.ent_iob_, X.ent_type_) for X in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def url_to_string(url):\n",
    "    \n",
    "    res = requests.get(url)\n",
    "    html = res.text\n",
    "   \n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    for script in soup([\"script\", \"style\", 'aside']):\n",
    "        script.extract()\n",
    "        \n",
    "    return \" \".join(re.split(r'[\\n\\t]+', soup.get_text()))\n",
    "\n",
    "ny_bb = url_to_string('https://www.nytimes.com/2018/08/13/us/politics/peter-strzok-fired-fbi.html?hp&action=click&pgtype=Homepage&clickSource=story-heading&module=first-column-region&region=top-news&WT.nav=top-news')\n",
    "\n",
    "type(ny_bb)\n",
    "article = nlp(ny_bb)\n",
    "len(article.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ORG': 38,\n",
       "         'PERSON': 77,\n",
       "         'DATE': 23,\n",
       "         'GPE': 9,\n",
       "         'NORP': 2,\n",
       "         'CARDINAL': 3,\n",
       "         'LOC': 1,\n",
       "         'ORDINAL': 1})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = [x.label_ for x in article.ents]\n",
    "Counter(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Strzok', 29), ('F.B.I.', 19), ('Trump', 13)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counter([(x.text,x.label_) for x in article.ents if x.label_ == 'ORG'])\n",
    "items = [x.text for x in article.ents]\n",
    "Counter(items).most_common(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aitan Goelman, Mr. Strzok’s lawyer, denounced his client’s dismissal.\n"
     ]
    }
   ],
   "source": [
    "sentences = [x for x in article.sents]\n",
    "print(sentences[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Aitan Goelman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", Mr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Strzok\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "’s lawyer, denounced his client’s dismissal.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(str(list(article.sents)[20])),jupyter = True,style = 'ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"cef3a054a13b424a9eb887acbebfdff3-0\" class=\"displacy\" width=\"1370\" height=\"377.0\" direction=\"ltr\" style=\"max-width: none; height: 377.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Aitan</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">Goelman,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">Mr.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">Strzok</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">’s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">lawyer,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">denounced</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">his</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">client</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">’s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">dismissal.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cef3a054a13b424a9eb887acbebfdff3-0-0\" stroke-width=\"2px\" d=\"M70,242.0 C70,182.0 155.0,182.0 155.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cef3a054a13b424a9eb887acbebfdff3-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,244.0 L62,232.0 78,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cef3a054a13b424a9eb887acbebfdff3-0-1\" stroke-width=\"2px\" d=\"M190,242.0 C190,2.0 770.0,2.0 770.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cef3a054a13b424a9eb887acbebfdff3-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M190,244.0 L182,232.0 198,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cef3a054a13b424a9eb887acbebfdff3-0-2\" stroke-width=\"2px\" d=\"M310,242.0 C310,182.0 395.0,182.0 395.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cef3a054a13b424a9eb887acbebfdff3-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M310,244.0 L302,232.0 318,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cef3a054a13b424a9eb887acbebfdff3-0-3\" stroke-width=\"2px\" d=\"M190,242.0 C190,122.0 400.0,122.0 400.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cef3a054a13b424a9eb887acbebfdff3-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,244.0 L408.0,232.0 392.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cef3a054a13b424a9eb887acbebfdff3-0-4\" stroke-width=\"2px\" d=\"M430,242.0 C430,182.0 515.0,182.0 515.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cef3a054a13b424a9eb887acbebfdff3-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M515.0,244.0 L523.0,232.0 507.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cef3a054a13b424a9eb887acbebfdff3-0-5\" stroke-width=\"2px\" d=\"M430,242.0 C430,122.0 640.0,122.0 640.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cef3a054a13b424a9eb887acbebfdff3-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M640.0,244.0 L648.0,232.0 632.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cef3a054a13b424a9eb887acbebfdff3-0-6\" stroke-width=\"2px\" d=\"M910,242.0 C910,182.0 995.0,182.0 995.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cef3a054a13b424a9eb887acbebfdff3-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910,244.0 L902,232.0 918,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cef3a054a13b424a9eb887acbebfdff3-0-7\" stroke-width=\"2px\" d=\"M1030,242.0 C1030,122.0 1240.0,122.0 1240.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cef3a054a13b424a9eb887acbebfdff3-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1030,244.0 L1022,232.0 1038,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cef3a054a13b424a9eb887acbebfdff3-0-8\" stroke-width=\"2px\" d=\"M1030,242.0 C1030,182.0 1115.0,182.0 1115.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cef3a054a13b424a9eb887acbebfdff3-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1115.0,244.0 L1123.0,232.0 1107.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cef3a054a13b424a9eb887acbebfdff3-0-9\" stroke-width=\"2px\" d=\"M790,242.0 C790,62.0 1245.0,62.0 1245.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cef3a054a13b424a9eb887acbebfdff3-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1245.0,244.0 L1253.0,232.0 1237.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(str(sentences[20])), style='dep', jupyter = True, options = {'distance': 120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 'SPACE', ' ',  ),\n",
       " ('F.B.I.', 'PROPN', 'F.B.I.', F.B.I.),\n",
       " ('Agent', 'PROPN', 'Agent', Agent),\n",
       " ('Peter', 'PROPN', 'Peter', Peter),\n",
       " ('Strzok', 'PROPN', 'Strzok', Strzok),\n",
       " ('Criticized', 'VERB', 'criticize', Criticized),\n",
       " ('Trump', 'PROPN', 'Trump', Trump),\n",
       " ('Texts', 'PROPN', 'Texts', Texts),\n",
       " ('Fired', 'VERB', 'fire', Fired),\n",
       " ('New', 'PROPN', 'New', New),\n",
       " ('York', 'PROPN', 'York', York),\n",
       " ('Times', 'PROPN', 'Times', Times),\n",
       " ('SectionsSEARCHSkip', 'PROPN', 'SectionsSEARCHSkip', SectionsSEARCHSkip),\n",
       " ('contentSkip', 'X', 'contentskip', contentSkip),\n",
       " ('site', 'VERB', 'site', site),\n",
       " ('indexPoliticsToday', 'PROPN', 'indexPoliticsToday', indexPoliticsToday),\n",
       " ('PaperPolitics|F.B.I.',\n",
       "  'PROPN',\n",
       "  'PaperPolitics|F.B.I.',\n",
       "  PaperPolitics|F.B.I.),\n",
       " ('Agent', 'PROPN', 'Agent', Agent),\n",
       " ('Peter', 'PROPN', 'Peter', Peter),\n",
       " ('Strzok', 'PROPN', 'Strzok', Strzok),\n",
       " ('Criticized', 'VERB', 'criticize', Criticized),\n",
       " ('Trump', 'PROPN', 'Trump', Trump),\n",
       " ('Texts', 'PROPN', 'Texts', Texts),\n",
       " ('Firedhttps://nyti.ms/2OtNre3AdvertisementContinue',\n",
       "  'NOUN',\n",
       "  'firedhttps://nyti.ms/2otnre3advertisementcontinue',\n",
       "  Firedhttps://nyti.ms/2OtNre3AdvertisementContinue),\n",
       " ('reading', 'VERB', 'read', reading),\n",
       " ('main', 'ADJ', 'main', main),\n",
       " ('storySupported', 'ADJ', 'storysupported', storySupported),\n",
       " ('byContinue', 'NOUN', 'bycontinue', byContinue),\n",
       " ('reading', 'VERB', 'read', reading),\n",
       " ('main', 'ADJ', 'main', main),\n",
       " ('storyF.B.I.', 'NOUN', 'storyf.b.i.', storyF.B.I.),\n",
       " ('Agent', 'PROPN', 'Agent', Agent),\n",
       " ('Peter', 'PROPN', 'Peter', Peter),\n",
       " ('Strzok', 'PROPN', 'Strzok', Strzok),\n",
       " ('Criticized', 'VERB', 'criticize', Criticized),\n",
       " ('Trump', 'PROPN', 'Trump', Trump),\n",
       " ('Texts', 'PROPN', 'Texts', Texts)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.orth_,x.pos_, x.lemma_,x) for x in [y \n",
    "                                      for y\n",
    "                                      in nlp(str(sentences[0])) \n",
    "                                      if not y.is_stop and y.pos_ != 'PUNCT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
